###############################################################################
# CORTEX-AI-ACT  —  Docker Compose (dev / CI / staging)
###############################################################################
# Usage:
#   docker compose up -d            # start all services
#   docker compose --profile gpu up # include GPU-enabled reasoning engine
#   docker compose down -v          # tear down & remove volumes
###############################################################################

name: cortex-ai-act

x-common-env: &common-env
  ENVIRONMENT: ${ENVIRONMENT:-development}
  LOG_LEVEL: ${LOG_LEVEL:-info}

services:
  # ===========================================================================
  # 1. NEO4J  —  Knowledge Graph database
  # ===========================================================================
  neo4j:
    image: neo4j:5.26-community
    container_name: cortex-neo4j
    restart: unless-stopped
    ports:
      - "${NEO4J_HTTP_PORT:-7474}:7474"   # Browser UI
      - "${NEO4J_BOLT_PORT:-7687}:7687"   # Bolt protocol
    environment:
      NEO4J_AUTH: ${NEO4J_USER:-neo4j}/${NEO4J_PASSWORD:-changeme}
      NEO4J_PLUGINS: '["apoc", "graph-data-science"]'
      NEO4J_server_memory_heap_initial__size: 512m
      NEO4J_server_memory_heap_max__size: 1G
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
      - ./docker/neo4j/init-cypher:/var/lib/neo4j/import
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:7474 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10
    networks:
      - cortex-net

  # ===========================================================================
  # 2. KNOWLEDGE-GRAPH SERVICE  —  PDF parsing, schema management, ingestion
  # ===========================================================================
  knowledge-graph:
    build:
      context: .
      dockerfile: services/knowledge-graph/Dockerfile
    container_name: cortex-knowledge-graph
    restart: unless-stopped
    ports:
      - "${KG_PORT:-8001}:8000"
    environment:
      <<: *common-env
      NEO4J_URI: bolt://neo4j:7687
      NEO4J_USER: ${NEO4J_USER:-neo4j}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD:-changeme}
    depends_on:
      neo4j:
        condition: service_healthy
    volumes:
      - ./services/knowledge-graph:/app
      - kg_cache:/app/.cache
    networks:
      - cortex-net

  # ===========================================================================
  # 3. REASONING-ENGINE SERVICE  —  LLM + LangGraph + Entropy Pruning
  # ===========================================================================
  reasoning-engine:
    build:
      context: .
      dockerfile: services/reasoning-engine/Dockerfile
    container_name: cortex-reasoning-engine
    restart: unless-stopped
    ports:
      - "${RE_PORT:-8002}:8000"
    environment:
      <<: *common-env
      NEO4J_URI: bolt://neo4j:7687
      NEO4J_USER: ${NEO4J_USER:-neo4j}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD:-changeme}
      HF_HOME: /app/.cache/huggingface
      MODEL_ID: ${MODEL_ID:-meta-llama/Meta-Llama-3.1-8B-Instruct}
    depends_on:
      neo4j:
        condition: service_healthy
    volumes:
      - ./services/reasoning-engine:/app
      - model_cache:/app/.cache
    networks:
      - cortex-net
    # Uncomment for GPU support (requires NVIDIA Container Toolkit)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]

  # ===========================================================================
  # 4. WEB-UI SERVICE  —  Streamlit / FastAPI dashboard
  # ===========================================================================
  web-ui:
    build:
      context: .
      dockerfile: services/web-ui/Dockerfile
    container_name: cortex-web-ui
    restart: unless-stopped
    ports:
      - "${UI_PORT:-8501}:8501"
    environment:
      <<: *common-env
      KG_SERVICE_URL: http://knowledge-graph:8000
      RE_SERVICE_URL: http://reasoning-engine:8000
    depends_on:
      - knowledge-graph
      - reasoning-engine
    volumes:
      - ./services/web-ui:/app
    networks:
      - cortex-net

  # ===========================================================================
  # 5. BENCHMARKING SERVICE  —  Sustainability & performance tracking
  # ===========================================================================
  benchmarking:
    build:
      context: .
      dockerfile: services/benchmarking/Dockerfile
    container_name: cortex-benchmarking
    restart: unless-stopped
    ports:
      - "${BENCH_PORT:-8003}:8000"
    environment:
      <<: *common-env
      RE_SERVICE_URL: http://reasoning-engine:8000
      KG_SERVICE_URL: http://knowledge-graph:8000
      WANDB_API_KEY: ${WANDB_API_KEY:-}
      MLFLOW_TRACKING_URI: ${MLFLOW_TRACKING_URI:-}
    depends_on:
      - reasoning-engine
    volumes:
      - ./services/benchmarking:/app
      - bench_results:/app/results
    networks:
      - cortex-net

  # ===========================================================================
  # 6. NGINX reverse proxy  (optional — for staging / production)
  # ===========================================================================
  nginx:
    image: nginx:1.27-alpine
    container_name: cortex-nginx
    restart: unless-stopped
    ports:
      - "${NGINX_PORT:-80}:80"
    volumes:
      - ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - web-ui
      - knowledge-graph
      - reasoning-engine
    profiles:
      - production
    networks:
      - cortex-net

# =============================================================================
# Volumes & Networks
# =============================================================================
volumes:
  neo4j_data:
  neo4j_logs:
  kg_cache:
  model_cache:
  bench_results:

networks:
  cortex-net:
    driver: bridge
